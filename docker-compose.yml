services:
  webapp:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      # API Keys (set these in .env file)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - SELF_OPENAI_API_KEY=${SELF_OPENAI_API_KEY}
      
      # Server Configuration
      - HOST=0.0.0.0
      - PORT=8000
      
      # Default LLM Settings
      - DEFAULT_MODEL=${DEFAULT_MODEL:-gpt-4o-mini}
      - DEFAULT_PROVIDER=${DEFAULT_PROVIDER:-openai}
      - DEFAULT_TEMPERATURE=${DEFAULT_TEMPERATURE:-0.0}
      - DEFAULT_CHUNK_SIZE=${DEFAULT_CHUNK_SIZE:-32768}
      - DEFAULT_CHUNK_OVERLAP=${DEFAULT_CHUNK_OVERLAP:-4096}
      - DEFAULT_FORMAT_TYPE=${DEFAULT_FORMAT_TYPE:-hybrid}
      - DEFAULT_PDF_PARSER=${DEFAULT_PDF_PARSER:-marker}
      - DEFAULT_MAX_CONCURRENT_CHUNKS=${DEFAULT_MAX_CONCURRENT_CHUNKS:-50}
      
      # File Upload Settings
      - MAX_FILE_SIZE=${MAX_FILE_SIZE:-52428800}  # 50MB
      - TEMP_DIR=/tmp/webapp_uploads
      
      # API Settings
      - API_TITLE=${API_TITLE:-MapReduce QA WebApp}
      - API_VERSION=${API_VERSION:-1.0.0}
    
    volumes:
      # Optional: Mount for persistent marker cache
      - marker_cache:/app/marker
      - pdf_cache:/app/pdf_cache
      # Optional: Mount for logs
      - ./webapp/logs:/app/logs
      # Optional: Mount for prompts customization
      - ./prompts:/app/prompts:ro
    
    env_file:
      - .env
    
    restart: unless-stopped
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

volumes:
  marker_cache:
    driver: local
  pdf_cache:
    driver: local

networks:
  default:
    name: mapreduce-qa-network